{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20073fdd-7589-4c22-a3b7-f73ecc7a0da3",
   "metadata": {},
   "source": [
    "# Dataclass Tutorial Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3128b3d3-05c3-44b4-b30c-64af6623a9b9",
   "metadata": {},
   "source": [
    "Here are some common use cases of `dataclass` in python.\n",
    "\n",
    "* **Storing Model Configurations:** Machine learning models often have various hyperparameters that can be tweaked. Dataclasses provide a clean way to define these configurations, making it easier to experiment with different settings and track results. For instance, you could create a dataclass to store learning rate, batch size, and optimizer settings for a neural network.\n",
    "\n",
    "* **Data Preprocessing Pipelines:** Data preprocessing is a crucial step in machine learning. Dataclasses can be used to represent the various stages of a preprocessing pipeline, including data normalization, feature scaling, and transformation. This imporves code readability and maintainability.\n",
    "\n",
    "* **Experiment Logging:** When running machine learning experiments, it's essential to keep track of the data used, model configurations, and performance metrics. Dataclasses can be used to create structured logs that capture this information, simplifying analysis and comparison of different runs.\n",
    "\n",
    "* **Feature Engineering:** Feature engineering involves creating new features from existing data. Dataclasses can be used to represent these new features, making it easier to track their origin and impact on model performance.\n",
    "\n",
    "\n",
    "**NOTE:** <font color='green'>Dataclasses promote clean, concise, and well-organized code for data-centric tasks in AI and machine learning. This improves readability, maintainability, and helps you manage complex data structures effectively.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a29fb-aaea-4ef4-8a60-a49c3d175297",
   "metadata": {},
   "source": [
    "## Example 1: Hyperparameter Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd105d5-3a1b-4635-89a3-1e92f34313ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters(learning_rate=0.001, batch_size=32, epochs=10)\n",
      "Hyperparameters(learning_rate=0.005, batch_size=8, epochs=100)\n",
      "====================\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Hyperparameters:\n",
    "    learning_rate: float = 0.01\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 100\n",
    "\n",
    "params = Hyperparameters(learning_rate=0.001,\n",
    "                         batch_size=32,\n",
    "                         epochs=10)\n",
    "params2 = Hyperparameters(learning_rate=0.005, \n",
    "                          batch_size=8)\n",
    "\n",
    "print(params)\n",
    "print(params2)\n",
    "print('='*20)\n",
    "print(params.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61081768-afbf-48f1-8ba9-1f7d4f6da2c1",
   "metadata": {},
   "source": [
    "## Example 2: Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a41e8c9a-c103-4e2d-88c4-488dd889a990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConfig(input_dim=100, hidden_dim=50, output_dim=10, activation='relu')\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    input_dim: int\n",
    "    hidden_dim: int\n",
    "    output_dim: int\n",
    "    activation: str\n",
    "\n",
    "config = ModelConfig(input_dim=100,\n",
    "                     hidden_dim=50,\n",
    "                     output_dim=10, \n",
    "                     activation='relu')\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1e4498a-3748-4229-a23f-23b37606c160",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Function `normalize_data` has not implemented.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m data \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m]]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m preprocessing_pipeline:\n\u001b[1;32m---> 23\u001b[0m   data \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m, in \u001b[0;36mnormalize_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_data\u001b[39m(data):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction `normalize_data` has not implemented.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Function `normalize_data` has not implemented."
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PreprocessingStep:\n",
    "  name: str\n",
    "  func: callable\n",
    "\n",
    "def normalize_data(data):\n",
    "    raise NotImplementedError('Function `normalize_data` has not implemented.')\n",
    "\n",
    "def scale_features(data):\n",
    "    raise NotImplementedError('Function `scale_featues` has not implemented.')\n",
    "\n",
    "# Example usage\n",
    "preprocessing_pipeline = [\n",
    "  PreprocessingStep(\"Normalization\", normalize_data),\n",
    "  PreprocessingStep(\"Feature Scaling\", scale_features),\n",
    "]\n",
    "\n",
    "data = [[1,3], [2, 5]]\n",
    "\n",
    "for step in preprocessing_pipeline:\n",
    "  data = step.func(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "842b6114-6ff6-4b96-b52e-500180c796e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentLog(model_name='MLP', hyperparameters=Hyperparameters(learning_rate=0.001, batch_size=32, epochs=10), training_time=120.5, accuracy=0.88)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ExperimentLog:\n",
    "    model_name: str\n",
    "    hyperparameters: Hyperparameters\n",
    "    training_time: float\n",
    "    accuracy: float\n",
    "\n",
    "log  = ExperimentLog(\"MLP\", params, 120.5, 0.88)\n",
    "\n",
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edf40e0c-d6fe-4ddb-a8a6-4ff44e194557",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NewFeature.__init__() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m original_feature2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5.0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m new_feature \u001b[38;5;241m=\u001b[39m \u001b[43mNewFeature\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRatio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43moriginal_feature1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_feature2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: NewFeature.__init__() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class NewFeature:\n",
    "  name: str\n",
    "  func: callable\n",
    "  # Optional: original_features (list of dataclasses referencing source features)\n",
    "\n",
    "def calculate_ratio(a, b):\n",
    "    try:\n",
    "        c = a/b\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "original_feature1 = [1, 2, 3]\n",
    "\n",
    "original_feature2 = [5.0, 3, 0]\n",
    "\n",
    "# Example usage\n",
    "new_feature = NewFeature(\"Ratio\", calculate_ratio, [original_feature1, original_feature2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "452b765e-0897-4857-ae3b-bebc56a8c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ratio(a, b):\n",
    "    try:\n",
    "        c = a/b\n",
    "        print(c)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79c47cb4-2e69-4700-8dde-3fa83d8b465f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "calculate_ratio(2,  1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8da01e7-446f-458e-a8b4-005e624683d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division by zero\n"
     ]
    }
   ],
   "source": [
    "calculate_ratio(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c8c0344-8c61-4264-8f5c-ad012aadd50a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Hyperparameters is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m log \u001b[38;5;241m=\u001b[39m ExperimentLog(model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      5\u001b[0m                     hyperparameters \u001b[38;5;241m=\u001b[39m params, \n\u001b[0;32m      6\u001b[0m                     training_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m120.5\u001b[39m, \n\u001b[0;32m      7\u001b[0m                     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.88\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_log.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Convert dataclass to dictionary for json\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type Hyperparameters is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# After experiment run\n",
    "log = ExperimentLog(model_name = \"MLP\", \n",
    "                    hyperparameters = params, \n",
    "                    training_time = 120.5, \n",
    "                    accuracy = 0.88)\n",
    "\n",
    "with open(\"experiment_log.json\", \"w\") as f:\n",
    "    json.dump(log.__dict__, f) # Convert dataclass to dictionary for json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e0a6686-d334-4ccc-a0a0-1f885eb39b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MLPConfig:\n",
    "  learning_rate: float = 0.01\n",
    "  batch_size: int = 32\n",
    "  epochs: int = 100\n",
    "  hidden_units: int = 64\n",
    "\n",
    "# Example usage\n",
    "config = MLPConfig(learning_rate=0.005, hidden_units=128)\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ExperimentLog:\n",
    "  model_name: str\n",
    "  config: MLPConfig\n",
    "  training_time: float\n",
    "  accuracy: float\n",
    "\n",
    "# Example usage\n",
    "log = ExperimentLog(\"MLP\", config, 120.5, 0.87)\n",
    "# You can then store or visualize this log information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cf07e8d-86eb-4927-a65e-17a1a18a7d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.005, 'batch_size': 32, 'epochs': 100, 'hidden_units': 128}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ... your experiment code ...\n",
    "\n",
    "# After experiment run\n",
    "log = ExperimentLog(model_name=\"MLP\", config=config, training_time=1100.0, accuracy=0.90)\n",
    "\n",
    "# Convert config dataclass to dictionary\n",
    "config_dict = log.config.__dict__\n",
    "\n",
    "print(config_dict)\n",
    "\n",
    "# Create the serializable dictionary for JSON\n",
    "log_dict = {\n",
    "    \"model_name\": log.model_name,\n",
    "    \"config\": config_dict,\n",
    "    \"training_time\": log.training_time,\n",
    "    \"accuracy\": log.accuracy\n",
    "}\n",
    "\n",
    "with open(\"experiment_log.json\", \"a\") as f:\n",
    "  json.dump(log_dict, f)  # Convert dataclass to dictionary for json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed11a810-c321-4b4a-99e6-84f6564fb682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
